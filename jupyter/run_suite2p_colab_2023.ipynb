{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agnijafaeh/mlclass/blob/main/jupyter/run_suite2p_colab_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMOvTOuH9Uyv",
        "outputId": "207c044f-6935-4666-c98a-8dddec0e8bc2",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless<4.3\n",
            "  Downloading opencv_python_headless-3.4.18.65-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless<4.3) (1.26.4)\n",
            "Downloading opencv_python_headless-3.4.18.65-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.10.0.84\n",
            "    Uninstalling opencv-python-headless-4.10.0.84:\n",
            "      Successfully uninstalled opencv-python-headless-4.10.0.84\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 3.4.18.65 which is incompatible.\n",
            "albumentations 1.4.20 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 3.4.18.65 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed opencv-python-headless-3.4.18.65\n",
            "Collecting suite2p\n",
            "  Downloading suite2p-0.14.4-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from suite2p) (8.5.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from suite2p) (8.4.0)\n",
            "Collecting rastermap>=0.9.0 (from suite2p)\n",
            "  Downloading rastermap-1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (from suite2p) (2024.9.20)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from suite2p) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from suite2p) (1.26.4)\n",
            "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.10/dist-packages (from suite2p) (0.60.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from suite2p) (3.8.0)\n",
            "Requirement already satisfied: scipy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from suite2p) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from suite2p) (1.5.2)\n",
            "Collecting cellpose (from suite2p)\n",
            "  Downloading cellpose-3.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting scanimage-tiff-reader>=1.4.1 (from suite2p)\n",
            "  Downloading scanimage-tiff-reader-1.4.1.4.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57.0->suite2p) (0.43.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from rastermap>=0.9.0->suite2p) (4.66.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->suite2p) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->suite2p) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->suite2p) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->suite2p) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->suite2p) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->suite2p) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.1->suite2p) (1.3.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from cellpose->suite2p) (3.4.18.65)\n",
            "Collecting fastremap (from cellpose->suite2p)\n",
            "  Downloading fastremap-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting imagecodecs (from cellpose->suite2p)\n",
            "  Downloading imagecodecs-2024.9.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting roifile (from cellpose->suite2p)\n",
            "  Downloading roifile-2024.9.15-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->suite2p) (3.21.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->suite2p) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->suite2p) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->suite2p) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->suite2p) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->suite2p) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->suite2p) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->suite2p) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->suite2p) (2.8.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->suite2p) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->suite2p) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->suite2p) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.1->suite2p) (3.0.2)\n",
            "Downloading suite2p-0.14.4-py3-none-any.whl (661 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.4/661.4 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rastermap-1.0-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.5/90.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cellpose-3.1.0-py3-none-any.whl (215 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.2/215.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastremap-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imagecodecs-2024.9.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading roifile-2024.9.15-py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: scanimage-tiff-reader\n",
            "  Building wheel for scanimage-tiff-reader (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scanimage-tiff-reader: filename=scanimage_tiff_reader-1.4.1.4-cp310-cp310-linux_x86_64.whl size=1092166 sha256=7f545333b783931bfb571be3a49c2f2b7dd11d23b8cdfabd77485bb5f1c09540\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/98/62/c1c5cc5e9c031ca500e8e6bb1e38d6e82de28f490f4e73ab94\n",
            "Successfully built scanimage-tiff-reader\n",
            "Installing collected packages: scanimage-tiff-reader, roifile, imagecodecs, fastremap, rastermap, cellpose, suite2p\n",
            "Successfully installed cellpose-3.1.0 fastremap-1.15.0 imagecodecs-2024.9.22 rastermap-1.0 roifile-2024.9.15 scanimage-tiff-reader-1.4.1.4 suite2p-0.14.4\n"
          ]
        }
      ],
      "source": [
        "!pip install \"opencv-python-headless<4.3\"\n",
        "!pip install suite2p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6cdRg0He9SRN"
      },
      "outputs": [],
      "source": [
        "import os, requests\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import suite2p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bH96eK729SRO",
        "outputId": "aa239563-126f-4fdb-8e26-1c5012ba505d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-1404daa3a31c>:14: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  jet = mpl.cm.get_cmap('jet')\n"
          ]
        }
      ],
      "source": [
        "# Figure Style settings for notebook.\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams.update({\n",
        "    'axes.spines.left': True,\n",
        "    'axes.spines.bottom': True,\n",
        "    'axes.spines.top': False,\n",
        "    'axes.spines.right': False,\n",
        "    'legend.frameon': False,\n",
        "    'figure.subplot.wspace': .01,\n",
        "    'figure.subplot.hspace': .01,\n",
        "    'figure.figsize': (18, 13),\n",
        "    'ytick.major.left': True,\n",
        "})\n",
        "jet = mpl.cm.get_cmap('jet')\n",
        "jet.set_bad(color='k')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFY4fVIL9SRO"
      },
      "source": [
        "# Running suite2p on example data\n",
        "\n",
        "This notebook will guide you through the various stages and outputs of suite2p by running it on a real-life dataset. This is data collected from a wild-type mouse injected with GCaMP6s in primary visual cortex. The recording was collected at 13Hz (there were 3 planes in the recording, 1 is included here).\n",
        "\n",
        "The next code cell downloads the data. You can also upload your own data to this folder on the left in the \"Files\" menu, or you can connect to your google drive (see instructions [here](https://colab.research.google.com/notebooks/io.ipynb)), which will make it easier to download the output files to your local computer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e-6J2maCaXZ",
        "outputId": "0b1c5814-2aca-4968-dddb-9a706c40fec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imaging data of shape:  (4500, 325, 556)\n"
          ]
        }
      ],
      "source": [
        "fname = \"gt1.tif\"\n",
        "url = \"https://www.suite2p.org/test_data/gt1.tif\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)\n",
        "\n",
        "from tifffile import imread\n",
        "data = imread(fname)\n",
        "print('imaging data of shape: ', data.shape)\n",
        "n_time, Ly, Lx = data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uab5XBO_9SRP"
      },
      "source": [
        "## Set pipeline parameters\n",
        "\n",
        "You can find an explanation of each op parameters [here](https://suite2p.readthedocs.io/en/latest/settings.html)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VE5t6namGAbj",
        "outputId": "6c3b35a4-2aea-4f19-a3c9-ba37edead5c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MT6NMQFT9SRP"
      },
      "outputs": [],
      "source": [
        "ops = suite2p.default_ops()\n",
        "ops['batch_size'] = 200 # we will decrease the batch_size in case low RAM on computer\n",
        "ops['threshold_scaling'] = 2.0 # we are increasing the threshold for finding ROIs to limit the number of non-cell ROIs found (sometimes useful in gcamp injections)\n",
        "ops['fs'] = 13 # sampling rate of recording, determines binning for cell detection\n",
        "ops['tau'] = 1.25 # timescale of gcamp to use for deconvolution\n",
        "print(ops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQtZ2kQ69SRQ"
      },
      "source": [
        "## Set Data Path\n",
        "`ops` and `db` are functionally equivalent internally in suite2p, with the exception that parameters provided in `db` will overwrite parameters specified in `ops`.\n",
        "\n",
        "**Tip**:  Since it's common to change datasets and keep the same parameters for each dataset, some might find it useful to specify data-related arguments in `db` and pipeline parameters in `ops`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1xgH7xO9SRQ"
      },
      "outputs": [],
      "source": [
        "db = {\n",
        "    'data_path': [os.getcwd()],\n",
        "}\n",
        "print(db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upbh98g-9SRQ"
      },
      "source": [
        "## Run Suite2p on Data\n",
        "\n",
        "The `suite2p.run_s2p` function runs the pipeline and returns a list of output dictionaries containing the pipeline parameters used and extra data calculated along the way, one for each plane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ogeYr309SRR"
      },
      "outputs": [],
      "source": [
        "output_ops = suite2p.run_s2p(ops=ops, db=db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDHISUwi9SRR"
      },
      "source": [
        "### Outputs from the Suite2p Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-6aRAFC9SRS"
      },
      "source": [
        "#### Ops dictionaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKIg1yHA9SRS"
      },
      "source": [
        "The ops dictionary contains all the keys that went into the analysis, plus new keys that contain additional metrics/outputs calculated during the pipeline run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RanSQ4OY9SRS"
      },
      "outputs": [],
      "source": [
        "print(set(output_ops.keys()).difference(ops.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPsOULww9SRT"
      },
      "source": [
        "#### Results Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyvMMwMc9SRT"
      },
      "outputs": [],
      "source": [
        "list(Path(output_ops['save_path']).iterdir())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM-A76s29SRT"
      },
      "source": [
        "The output parameters can also be found in the \"ops.npy\" file.  This is especially useful when running the pipeline from the terminal or the graphical interface.  It contains the same data that is output from the python `run_s2p()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1FBq87w9SRT"
      },
      "outputs": [],
      "source": [
        "output_ops_file = np.load(Path(output_ops['save_path']).joinpath('ops.npy'), allow_pickle=True).item()\n",
        "output_ops_file.keys() == output_ops.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG-gzu4k9SRT"
      },
      "source": [
        "The other files will be used for the visualizations in the section below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxux9jgFYsDK"
      },
      "source": [
        "## Running individual Suite2P modules\n",
        "While `suite2p.run_s2p` runs the entire pipeline, you may instead want to run individual modules (e.g., registration, cell detection, extraction, etc.). In this section, we'll go over the steps to run the following individual modules.\n",
        "\n",
        "1. Registration\n",
        "2. ROI detection\n",
        "3. Signal Extraction\n",
        "4. Classification of ROIs\n",
        "5. Spike Deconvolution\n",
        "\n",
        "To run `registration`, `detection`, and `extraction` separately, we must first talk about a special class in `suite2p` called a `BinaryFile`. You can think of `BinaryFile` as a class for reading/writing image data that acts like a numpy array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SABzwikPYsDK"
      },
      "source": [
        "### Running Registration\n",
        "\n",
        "To run registration alone (called by the `register.registration_wrapper` function in the registration module), we'll first instantiate the necessary parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00s-KhXFYsDK"
      },
      "outputs": [],
      "source": [
        "# Read in raw tif corresponding to our example tif\n",
        "f_raw = suite2p.io.BinaryFile(Ly=Ly, Lx=Lx, filename=fname)\n",
        "# Create a binary file we will write our registered image to\n",
        "f_reg = suite2p.io.BinaryFile(Ly=Ly, Lx=Lx, filename='registered_data.bin', n_frames = f_raw.shape[0]) # Set registered binary file to have same n_frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0idbURhWYsDM"
      },
      "source": [
        "We'll run the registration module only on our example image which only contains data from a single channel. You can add in data for the second channel (e.g., `f_reg_chan2` and `f_raw_chan2`) using similar code to what we have above. When writing a new `BinaryFile`, please make sure to specify the number of frames your `BinaryFile` instance will have. Refer to the docs to see what the outputs refer to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZa_Lr-4YsDM"
      },
      "outputs": [],
      "source": [
        "refImg, rmin, rmax, meanImg, rigid_offsets, \\\n",
        "nonrigid_offsets, zest, meanImg_chan2, badframes, \\\n",
        "yrange, xrange = suite2p.registration_wrapper(f_reg, f_raw=f_raw, f_reg_chan2=None,\n",
        "                                                   f_raw_chan2=None, refImg=None,\n",
        "                                                   align_by_chan2=False, ops=ops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OExMXfvfYsDN"
      },
      "source": [
        "### Running ROI Detection\n",
        "\n",
        "To run ROI detection alone (called by the `detection_wrapper` function in the detection module), we'll first instantiate the necessary parameters. You only need a `BinaryRWFile` corresponding to a registered/unregistered recording. Here, we'll pass the `f_reg` we obtained after running the registration module above.\n",
        "\n",
        "Suite2p provides a default classification file containing a default dataset that is used to train a classifier that will be used for your data. One could specify their own classification file if they'd like. To do so, they should save a numpy file with a dict containing the following keys:\n",
        "- `'stats'`: ROI Stats\n",
        "- `'keys'`: keys of ROI stats that will be used for classification\n",
        "- `'iscell'`: labels specifying whether an ROI is a cell or not\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k56CHDKYYsDN"
      },
      "outputs": [],
      "source": [
        "# Use default classification file provided by suite2p\n",
        "classfile = suite2p.classification.builtin_classfile\n",
        "np.load(classfile, allow_pickle=True)[()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVOPEcIWYsDN"
      },
      "outputs": [],
      "source": [
        "ops, stat = suite2p.detection_wrapper(f_reg=f_reg, ops=ops, classfile=classfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No20is38YsDN"
      },
      "source": [
        "### Running Fluorescence Extraction\n",
        "To run extraction alone (called by the `extraction_wrapper` function in the extraction module), we can just make use of any `stat` dictionary (from previous runs of suite2p or a custom user-made one). In this case, we'll use the one output by the cell above. If you'd like to extract signal, you can pass a `binaryFile` corresponding to the recording for the second channel to the `f_reg_chan2` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ-19MUiYsDO"
      },
      "outputs": [],
      "source": [
        "stat_after_extraction, F, Fneu, F_chan2, Fneu_chan2 = suite2p.extraction_wrapper(stat, f_reg,\n",
        "                                                                   f_reg_chan2 = None,ops=ops)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFauoeukYsDO"
      },
      "source": [
        "### Running Cell classification\n",
        "To run cell classification(called by the `classify` function in the classification module), we just need a `stat` dictionary and `classfile`.\n",
        "\n",
        "**Important**: The `stat` dictionary used in the classification module should not be the same as the one used in extraction. The `stat` used for classification requires a few more keys which are added after the extraction step.\n",
        "\n",
        "We'll use `stat_after_extraction` from the output of the extraction cell above and the same `classfile` used above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzWadEUoYsDP"
      },
      "outputs": [],
      "source": [
        "iscell = suite2p.classify(stat=stat_after_extraction, classfile=classfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDphsfGrYsDP"
      },
      "source": [
        "### Running Spike Deconvolution\n",
        "\n",
        "To run spike deconvolution (called by the `oasis` function in the extraction module), we need to first run the preprocess step. To do so, we'll need `dF` which consist of the fluorescence traces for our cells after neuropil correction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmCu3OgZYsDQ"
      },
      "outputs": [],
      "source": [
        "# Correct our fluorescence traces\n",
        "dF = F.copy() - ops['neucoeff']*Fneu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3ryUQgWYsDQ"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing step for deconvolution\n",
        "dF = suite2p.extraction.preprocess(\n",
        "        F=dF,\n",
        "        baseline=ops['baseline'],\n",
        "        win_baseline=ops['win_baseline'],\n",
        "        sig_baseline=ops['sig_baseline'],\n",
        "        fs=ops['fs'],\n",
        "        prctile_baseline=ops['prctile_baseline']\n",
        "    )\n",
        "# Identify spikes\n",
        "spks = suite2p.extraction.oasis(F=dF, batch_size=ops['batch_size'], tau=ops['tau'], fs=ops['fs'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA1RBMpT9SRU"
      },
      "source": [
        "\n",
        "## Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98XwDWFi9SRU"
      },
      "source": [
        "### Registration\n",
        "\n",
        "Registration computes a reference image from a subset of frames and registers all frames to the reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4dULbWk9SRU"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1, 4, 1)\n",
        "\n",
        "plt.imshow(output_ops['refImg'], cmap='gray', )\n",
        "plt.title(\"Reference Image for Registration\");\n",
        "\n",
        "# maximum of recording over time\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.imshow(output_ops['max_proj'], cmap='gray')\n",
        "plt.title(\"Registered Image, Max Projection\");\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.imshow(output_ops['meanImg'], cmap='gray')\n",
        "plt.title(\"Mean registered image\")\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.imshow(output_ops['meanImgE'], cmap='gray')\n",
        "plt.title(\"High-pass filtered Mean registered image\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RO29zSnbVsG"
      },
      "source": [
        "The rigid offsets of the frame from the reference are saved in `output_ops['yoff']` and `output_ops['xoff']`. The nonrigid offsets are saved in `output_ops['yoff1']` and `output_ops['xoff1']`, and each column is the offsets for a block (128 x 128 pixels by default)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYLlovO8bU9K"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,8))\n",
        "\n",
        "plt.subplot(4,1,1)\n",
        "plt.plot(output_ops['yoff'][:1000])\n",
        "plt.ylabel('rigid y-offsets')\n",
        "\n",
        "plt.subplot(4,1,2)\n",
        "plt.plot(output_ops['xoff'][:1000])\n",
        "plt.ylabel('rigid x-offsets')\n",
        "\n",
        "plt.subplot(4,1,3)\n",
        "plt.plot(output_ops['yoff1'][:1000])\n",
        "plt.ylabel('nonrigid y-offsets')\n",
        "\n",
        "plt.subplot(4,1,4)\n",
        "plt.plot(output_ops['xoff1'][:1000])\n",
        "plt.ylabel('nonrigid x-offsets')\n",
        "plt.xlabel('frames')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "68k4jtcP89MC"
      },
      "outputs": [],
      "source": [
        "#@title Run cell to look at registered frames\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "from suite2p.io import BinaryFile\n",
        "\n",
        "widget = widgets.IntSlider(\n",
        "    value=7,\n",
        "    min=0,\n",
        "    max=10,\n",
        "    step=1,\n",
        "    description='Test:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='d'\n",
        ")\n",
        "\n",
        "\n",
        "def plot_frame(t):\n",
        "    with BinaryFile(Ly=output_ops['Ly'],\n",
        "                Lx=output_ops['Lx'],\n",
        "                filename=output_ops['reg_file']) as f:\n",
        "        plt.imshow(f[t])\n",
        "\n",
        "interact(plot_frame, t=(0, output_ops['nframes']- 1, 1)); # zero-indexed so have to subtract 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JYnh7nBYxKW"
      },
      "source": [
        "Here in the notebook is not the best/fastest way to play the movie, you can play it in the suite2p GUI in the \"View registered binary\" player."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a01HMnop9SRU"
      },
      "source": [
        "### Detection\n",
        "\n",
        "ROIs are found by searching for sparse signals that are correlated spatially in the FOV. The ROIs are saved in `stat.npy` as a list of dictionaries which contain the pixels of the ROI and their weights (`stat['ypix']`, `stat['xpix']`, and `stat['lam']`). It also contains other spatial properties of the ROIs such as their aspect ratio and compactness, and properties of the signal such as the skewness of the fluorescence signal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZ2eiCpG9SRU"
      },
      "outputs": [],
      "source": [
        "stats_file = Path(output_ops['save_path']).joinpath('stat.npy')\n",
        "iscell = np.load(Path(output_ops['save_path']).joinpath('iscell.npy'), allow_pickle=True)[:, 0].astype(int)\n",
        "stats = np.load(stats_file, allow_pickle=True)\n",
        "print(stats[0].keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iOjYZSpYeAr"
      },
      "source": [
        "Some ROIs are defined as \"cells\" (somatic ROIs) or \"not cells\" (all other ROIs) depending on their properties, like skewness, compactness, etc. Below we will visualize the ROIs, but please open the files in the suite2p GUI for closer inspection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BuFviJR9SRV"
      },
      "outputs": [],
      "source": [
        "n_cells = len(stats)\n",
        "\n",
        "h = np.random.rand(n_cells)\n",
        "hsvs = np.zeros((2, Ly, Lx, 3), dtype=np.float32)\n",
        "\n",
        "for i, stat in enumerate(stats):\n",
        "    ypix, xpix, lam = stat['ypix'], stat['xpix'], stat['lam']\n",
        "    hsvs[iscell[i], ypix, xpix, 0] = h[i]\n",
        "    hsvs[iscell[i], ypix, xpix, 1] = 1\n",
        "    hsvs[iscell[i], ypix, xpix, 2] = lam / lam.max()\n",
        "\n",
        "from colorsys import hsv_to_rgb\n",
        "rgbs = np.array([hsv_to_rgb(*hsv) for hsv in hsvs.reshape(-1, 3)]).reshape(hsvs.shape)\n",
        "\n",
        "plt.figure(figsize=(18,18))\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.imshow(output_ops['max_proj'], cmap='gray')\n",
        "plt.title(\"Registered Image, Max Projection\")\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.imshow(rgbs[1])\n",
        "plt.title(\"All Cell ROIs\")\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.imshow(rgbs[0])\n",
        "plt.title(\"All non-Cell ROIs\");\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAkuc_up9SRV"
      },
      "source": [
        "### Traces\n",
        "\n",
        "We will load in the fluorescence, the neuropil and the deconvolved traces, and visualize them for a few cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s7r6Ny99SRV"
      },
      "outputs": [],
      "source": [
        "f_cells = np.load(Path(output_ops['save_path']).joinpath('F.npy'))\n",
        "f_neuropils = np.load(Path(output_ops['save_path']).joinpath('Fneu.npy'))\n",
        "spks = np.load(Path(output_ops['save_path']).joinpath('spks.npy'))\n",
        "f_cells.shape, f_neuropils.shape, spks.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29Wr9tUz9SRV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[20,20])\n",
        "plt.suptitle(\"Fluorescence and Deconvolved Traces for Different ROIs\", y=0.92);\n",
        "rois = np.arange(len(f_cells))[::200]\n",
        "for i, roi in enumerate(rois):\n",
        "    plt.subplot(len(rois), 1, i+1, )\n",
        "    f = f_cells[roi]\n",
        "    f_neu = f_neuropils[roi]\n",
        "    sp = spks[roi]\n",
        "    # Adjust spks range to match range of fluroescence traces\n",
        "    fmax = np.maximum(f.max(), f_neu.max())\n",
        "    fmin = np.minimum(f.min(), f_neu.min())\n",
        "    frange = fmax - fmin\n",
        "    sp /= sp.max()\n",
        "    sp *= frange\n",
        "    plt.plot(f, label=\"Cell Fluorescence\")\n",
        "    plt.plot(f_neu, label=\"Neuropil Fluorescence\")\n",
        "    plt.plot(sp + fmin, label=\"Deconvolved\")\n",
        "    plt.xticks(np.arange(0, f_cells.shape[1], f_cells.shape[1]/10))\n",
        "    plt.ylabel(f\"ROI {roi}\", rotation=0)\n",
        "    plt.xlabel(\"frame\")\n",
        "    if i == 0:\n",
        "        plt.legend(bbox_to_anchor=(0.93, 2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "run_suite2p_colab_2021.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}